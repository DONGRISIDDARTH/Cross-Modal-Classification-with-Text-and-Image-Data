# -*- coding: utf-8 -*-
"""ImageProcessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VUWuNtP03WjoHJHvDCJt0uxxElcuQLZ0
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
import keras

from keras.models import Sequential, Model
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, TensorBoard, CSVLogger
from keras import backend as K
from keras.applications.inception_v3 import InceptionV3

# from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential, Model
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau
from keras.callbacks import TensorBoard
from keras import backend as K
from keras.callbacks import CSVLogger
from keras.applications.inception_v3 import InceptionV3

# Loading images from Google Drive
from google.colab import drive
drive.mount("/content/drive")
train_data_dir = '/content/drive/My Drive/pro/images/train'
validation_data_dir = '/content/drive/My Drive/pro/images/test'
nb_train_samples = 79680
nb_validation_samples = 20120
n_classes = 101
epochs = 10
batch_size=250

# Checking image format: if RGB channel is coming first or last so, model will check first and then input shape will be feeded accordingly.
img_width = 299
img_height = 299

if K.image_data_format() == 'channels_first':
    input_shape = (3, img_width, img_height)
else:
    input_shape = (img_width, img_height, 3)

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, AveragePooling2D, Dropout, Flatten, Dense
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.regularizers import l2, l1

# start

from keras.applications import InceptionResNetV2
from keras.layers import Input

# Create Inception-ResNetV2 base model
base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(299, 299, 3)))

x = base_model.output
x = AveragePooling2D(pool_size=(8, 8))(x)
x = Dropout(0.4)(x)
x = Flatten()(x)

predictions = Dense(n_classes,
                    kernel_regularizer=l2(0.005),
                    activity_regularizer=l1(0.005),
                    activation='softmax')(x)

# Create the model
model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model using Stochastic Gradiend Descent (SGD) optimizer
from keras.optimizers import SGD
model.compile(
    optimizer=SGD(learning_rate=0.01, momentum=0.9),
    loss='categorical_crossentropy',
    metrics=['accuracy'])

# Train & Test Data Generators with image augmentation
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)
    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)
    horizontal_flip=True,  # randomly flip images
    zoom_range=[.8, 1],
    channel_shift_range=30,
    fill_mode='reflect')

test_datagen = ImageDataGenerator()

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    seed = 11,
    class_mode='categorical')

validation_generator = test_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    seed = 11,
    class_mode='categorical')

from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger
from tensorflow.keras import callbacks  # Ensure callbacks module is imported

checkpoint_path = "/content/drive/My Drive/DL_project/imagesweights/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5"
cp = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1, mode='max')
csv_logger = callbacks.CSVLogger('/content/drive/My Drive/DL_project/imagesweights/images/inceptionresnetv2.log')
# Reduce LR if no improvement on the test accuracy is observed
reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1,
                              patience=2, min_lr=0.00001)

#Fitting
model.fit(train_generator,
          steps_per_epoch = nb_train_samples // batch_size,
          validation_data=validation_generator,
          validation_steps=nb_validation_samples // batch_size,
          epochs=epochs,
          verbose=1,
          callbacks=[cp,reduce_lr]
          )

#Evaluation
score = model.evaluate_generator(
    validation_generator,
    nb_validation_samples/batch_size)

print(score)
