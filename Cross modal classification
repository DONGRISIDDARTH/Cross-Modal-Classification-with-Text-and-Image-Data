# -*- coding: utf-8 -*-
"""crossmodal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IZhneomKsX9icEoUwk7a_0sc1zKTS8-b

# Text classification model
"""

# Install BERT for tf2 module
!pip install bert-for-tf2
# Install sentencepiece library for text cleaning
!pip install sentencepiece

# Commented out IPython magic to ensure Python compatibility.
# Import all necessary libraries
try:
#     %tensorflow_version 2.x
except Exception:
    pass

import tensorflow as tf
import tensorflow_hub as hub
from tensorflow.keras import layers
from tensorflow.keras import callbacks
from tensorflow.keras import optimizers
from tensorflow.keras import utils
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import shuffle
import bert
import os
import numpy as np
import re
import pandas as pd
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go

!pip install pandas numpy scikit-learn nltk spacy gensim wordcloud

# Import the training and test .csv files
import pandas as pd
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive',force_remount=True)

# Path to your CSV file
csv_file_path_train = "/content/drive/My Drive/pro/texts/train_data.csv"
csv_file_path_test = "/content/drive/My Drive/pro/texts/test_data.csv"

colnames=['image_path', 'text', 'food']
train = pd.read_csv(csv_file_path_train, names=colnames, header=None, sep = ',', index_col=['image_path'])
test = pd.read_csv(csv_file_path_test, names=colnames, header=None, sep = ',', index_col=['image_path'])

# # Sort values by 'image_path'
# test = test.sort_values('image_path')
# train = train.sort_values('image_path')

# train['food'].value_counts()

# train.head()

# # Check the shapes
# print("train samples:",train.shape[0])
# print("test samples:",test.shape[0])

# Cleaning text function

def preprocess_text(sen):
    # Removing html tags
    sentence = remove_tags(sen)

    # Remove punctuations and numbers
    sentence = re.sub('[^a-zA-Z]', ' ', sentence)

    # Single character removal
    sentence = re.sub(r"\s+[a-zA-Z]\s+", ' ', sentence)

    # Removing multiple spaces
    sentence = re.sub(r'\s+', ' ', sentence)

    sentence = sentence.lower()

    return sentence

def remove_tags(text):
    return TAG_RE.sub('', text)

TAG_RE = re.compile(r'<[^>]+>')
vec_preprocess_text = np.vectorize(preprocess_text)

# Check number of classes
nClasses = train.food.nunique()
# nClasses

encoder = LabelEncoder()
processed_train = vec_preprocess_text(train.text.values)
processed_test = vec_preprocess_text(test.text.values)


encoded_labels_train = encoder.fit_transform(train.food.values)
labels_train = utils.to_categorical(encoded_labels_train, nClasses)

encoded_labels_test = encoder.fit_transform(test.food.values)
labels_test = utils.to_categorical(encoded_labels_test, nClasses)

# Import the BERT BASE model from Tensorflow HUB (layer, vocab_file and tokenizer)
BertTokenizer = bert.bert_tokenization.FullTokenizer
bert_layer = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1",trainable=False)
vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()
to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()
tokenizer = BertTokenizer(vocabulary_file, to_lower_case)

# Preprocessing of texts according to BERT

def get_masks(text, max_length):
    """Mask for padding"""
    tokens = tokenizer.tokenize(text)
    tokens = ["[CLS]"] + tokens + ["[SEP]"]
    length = len(tokens)
    if length > max_length:
        tokens = tokens[:max_length]

    return np.asarray([1]*len(tokens) + [0] * (max_length - len(tokens)))
vec_get_masks = np.vectorize(get_masks, signature = '(),()->(n)')

def get_segments(text, max_length):
    """Segments: 0 for the first sequence, 1 for the second"""
    tokens = tokenizer.tokenize(text)
    tokens = ["[CLS]"] + tokens + ["[SEP]"]
    length = len(tokens)
    if length > max_length:
        tokens = tokens[:max_length]

    segments = []
    current_segment_id = 0
    with_tags = ["[CLS]"] + tokens + ["[SEP]"]
    token_ids = tokenizer.convert_tokens_to_ids(tokens)

    for token in tokens:
        segments.append(current_segment_id)
        if token == "[SEP]":
            current_segment_id = 1
    return np.asarray(segments + [0] * (max_length - len(tokens)))
vec_get_segments = np.vectorize(get_segments, signature = '(),()->(n)')

def get_ids(text, tokenizer, max_length):
    """Token ids from Tokenizer vocab"""
    tokens = tokenizer.tokenize(text)
    tokens = ["[CLS]"] + tokens + ["[SEP]"]
    length = len(tokens)
    if length > max_length:
        tokens = tokens[:max_length]

    token_ids = tokenizer.convert_tokens_to_ids(tokens)
    input_ids = np.asarray(token_ids + [0] * (max_length-length))
    return input_ids
vec_get_ids = np.vectorize(get_ids, signature = '(),(),()->(n)')


def prepare(text_array, tokenizer, max_length = 128):

    ids = vec_get_ids(text_array,
                      tokenizer,
                      max_length).squeeze()
    masks = vec_get_masks(text_array,
                      max_length).squeeze()
    segments = vec_get_segments(text_array,
                      max_length).squeeze()

    return ids, segments, masks

max_length = 30 # that must be set according to your dataset
ids_train, segments_train, masks_train = prepare(processed_train,tokenizer,max_length)
ids_test, segments_test, masks_test = prepare(processed_test,tokenizer,max_length)

input_word_ids = layers.Input(shape=(max_length,), dtype=tf.int32,
                                       name="input_word_ids")
input_mask = layers.Input(shape=(max_length,), dtype=tf.int32,
                                   name="input_mask")
segment_ids = layers.Input(shape=(max_length,), dtype=tf.int32,
                                    name="segment_ids")
den_out, seq_out = bert_layer([input_word_ids, input_mask, segment_ids])

# Attention layer
from keras import backend as K

class AttentionLayer(layers.Layer):
    def __init__(self, **kwargs):
        super(AttentionLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        self.W = self.add_weight(name="att_weight", shape=(input_shape[-1], 1), initializer="normal")
        self.b = self.add_weight(name="att_bias", shape=(input_shape[1], 1), initializer="zeros")
        super(AttentionLayer, self).build(input_shape)

    def call(self, x):
        et = K.squeeze(K.tanh(K.dot(x, self.W) + self.b), axis=-1)
        at = K.softmax(et)
        at = K.expand_dims(at, axis=-1)
        output = x * at
        return K.sum(output, axis=1)

# X = AttentionLayer()(X)

import tensorflow as tf
from tensorflow.keras import layers, models

class WordAttention(layers.Layer):
    def __init__(self, units):
        super(WordAttention, self).__init__()
        self.W = layers.Dense(units)
        self.V = layers.Dense(1)

    def call(self, inputs):
        # inputs shape: (batch_size, max_length, embedding_dim)
        score = tf.nn.tanh(self.W(inputs))
        attention_weights = tf.nn.softmax(self.V(score), axis=1)
        context_vector = attention_weights * inputs
        context_vector = tf.reduce_sum(context_vector, axis=1)
        return context_vector, attention_weights

class SentenceAttention(layers.Layer):
    def __init__(self, units):
        super(SentenceAttention, self).__init__()
        self.W = layers.Dense(units)
        self.V = layers.Dense(1)

    def call(self, inputs):
        # inputs shape: (batch_size, num_sentences, sentence_embedding_dim)
        score = tf.nn.tanh(self.W(inputs))
        attention_weights = tf.nn.softmax(self.V(score), axis=1)
        sentence_vector = attention_weights * inputs
        sentence_vector = tf.reduce_sum(sentence_vector, axis=1)
        return sentence_vector, attention_weights

from tensorflow.keras import layers

# Define input layers
input_word_ids = layers.Input(shape=(max_length,), dtype=tf.int32, name="input_word_ids")
input_mask = layers.Input(shape=(max_length,), dtype=tf.int32, name="input_mask")
segment_ids = layers.Input(shape=(max_length,), dtype=tf.int32, name="segment_ids")

# BERT layer
_, seq_out = bert_layer([input_word_ids, input_mask, segment_ids])

# Sentence-level attention
sentence_context_vector, _ = SentenceAttention(128)(seq_out)

# Reshape sentence context vector to add a sequence dimension
sentence_context_expanded = layers.Reshape((-1, 128))(sentence_context_vector)

# Bidirectional GRU layer after sentence-level attention
bidirectional_gru_out = layers.Bidirectional(layers.GRU(128, return_sequences=True))(sentence_context_expanded)

# Hierarchical attention
document_context_vector, _ = WordAttention(128)(bidirectional_gru_out)

# Reshape the document context vector to make it compatible with the Dense layer
document_context_vector_expanded = layers.Reshape((-1,))(document_context_vector)

# Additional dense layers
dense_out_1 = layers.Dense(256, activation="relu")(document_context_vector_expanded)
dense_dropout_out_1 = layers.Dropout(0.5)(dense_out_1)

# Output layer
output = layers.Dense(nClasses, activation='softmax')(dense_dropout_out_1)

# Define the model
model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=output)

# Adam optimizer
opt = optimizers.Adam(learning_rate=0.01)

# AdamW
from tensorflow.keras import optimizers

# opt = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='AdamW')


# Compile model
model.compile(loss = 'categorical_crossentropy',
              optimizer = opt,
              metrics = ['accuracy'])

# model.summary()

es = callbacks.EarlyStopping(monitor='val_accuracy', patience=2, restore_best_weights=True)

# Setup callbacks, logs and early stopping condition
checkpoint_path = "/content/drive/My Drive/DL_project/textweights/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5"
cp = callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy',save_best_only=True,verbose=1, mode='max')
csv_logger = callbacks.CSVLogger('/content/drive/My Drive/DL_project/textweights/bert_hans_gru.log')
es = callbacks.EarlyStopping(patience = 3, restore_best_weights=True)

# Reduce learning rate if no improvement is observed
reduce_lr = callbacks.ReduceLROnPlateau(
    monitor='val_accuracy', factor=0.1, patience=1, min_lr=0.00001)

from keras.callbacks import ReduceLROnPlateau, EarlyStopping

# Define ReduceLROnPlateau callback
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6, verbose=1)

# Define EarlyStopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# # Train the model with ReduceLROnPlateau and EarlyStopping callbacks
# history = model.fit([ids_train, masks_train, segments_train],
#                     labels_train,
#                     epochs=16,
#                     batch_size=30,
#                     validation_split=0.3,
#                     callbacks=[cp, reduce_lr, early_stopping])



"""## Image processing"""

# # Install Keras version 2.3.1
# # !pip install keras==2.3.1
# !pip install tensorflow
# !pip install --upgrade keras

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
import keras
# print(tf.__version__)
# print(keras.__version__)

import os
from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, MaxPooling1D, GlobalAveragePooling2D
from keras.layers import Activation, Dropout, Flatten, Dense, Input
from keras.optimizers import Adam, SGD, Adadelta
from keras.regularizers import l2, l1
import cv2
import sys
import time
import pickle
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import matplotlib.pyplot as plt
from keras.applications.inception_v3 import InceptionV3

from keras.models import Sequential, Model
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, TensorBoard, CSVLogger
from keras import backend as K
from keras.applications.inception_v3 import InceptionV3

# from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential, Model
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau
from keras.callbacks import TensorBoard
from keras import backend as K
from keras.callbacks import CSVLogger
from keras.applications.inception_v3 import InceptionV3

# Loading images from Google Drive
from google.colab import drive
drive.mount("/content/drive")
train_data_dir = '/content/drive/My Drive/pro/images/train'
validation_data_dir = '/content/drive/My Drive/pro/images/test'
nb_train_samples = 7968
nb_validation_samples = 2012
n_classes = 45
epochs = 10
batch_size=40

# Checking image format: if RGB channel is coming first or last so, model will check first and then input shape will be feeded accordingly.
img_width = 299
img_height = 299

if K.image_data_format() == 'channels_first':
    input_shape = (3, img_width, img_height)
else:
    input_shape = (img_width, img_height, 3)

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, AveragePooling2D, Dropout, Flatten, Dense
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.regularizers import l2, l1

# star

from keras.applications import InceptionResNetV2
from keras.layers import Input

# Create Inception-ResNetV2 base model
base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(299, 299, 3)))

x = base_model.output
x = AveragePooling2D(pool_size=(8, 8))(x)
x = Dropout(0.4)(x)
x = Flatten()(x)

predictions = Dense(n_classes,
                    kernel_regularizer=l2(0.005),
                    activity_regularizer=l1(0.005),
                    activation='softmax')(x)

# Create the model
model = Model(inputs=base_model.input, outputs=predictions)

#from tensorflow.keras.utils import plot_model
#plot_model(model, to_file='model_cnn.png')

# Compile the model using Stochastic Gradiend Descent (SGD) optimizer
model.compile(
    optimizer=SGD(learning_rate=0.01, momentum=0.9),
    loss='categorical_crossentropy',
    metrics=['accuracy'])

# Plot the model and save to file
#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

# Train & Test Data Generators with image augmentation
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)
    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)
    horizontal_flip=True,  # randomly flip images
    zoom_range=[.8, 1],
    channel_shift_range=30,
    fill_mode='reflect')

test_datagen = ImageDataGenerator()

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    seed = 11,
    class_mode='categorical')

validation_generator = test_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    seed = 11,
    class_mode='categorical')

from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger
from tensorflow.keras import callbacks  # Ensure callbacks module is imported

checkpoint_path = "/content/drive/My Drive/DL_project/imagesweights/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5"
cp = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1, mode='max')
csv_logger = callbacks.CSVLogger('/content/drive/My Drive/DL_project/imagesweights/images/inceptionresnetv2.log')

# Reduce LR if no improvement on the test accuracy is observed
reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1,
                              patience=2, min_lr=0.00001)



"""# combination"""

model_cnn = models.Model(base_model.input, predictions, name='Image_Model')
# Load Images model weights
model_cnn.load_weights('/content/drive/My Drive/DL_project/imagesweights/weights-improvement-04-0.59.hdf5')
# Freeze the images model layers
for layer in model_cnn.layers:
    layer.trainable = False

model_lstm = models.Model([input_word_ids, input_mask, segment_ids], output, name='Bert_Model')

model_lstm.load_weights('/content/drive/My Drive/DL_project/textweights/weights-improvement-08-0.85.hdf5')
for layer in model_lstm.layers:
    layer.trainable = False

# Multimodal combined
input_word_ids = layers.Input(shape=(max_length,), dtype=tf.int32,
                                       name="input_word_ids")
input_mask = layers.Input(shape=(max_length,), dtype=tf.int32,
                                   name="input_mask")
segment_ids = layers.Input(shape=(max_length,), dtype=tf.int32,
                                    name="segment_ids")
image_input = layers.Input(shape = input_shape, dtype=tf.float32,
                           name = "image")

image_side = model_cnn(image_input)
text_side = model_lstm([input_word_ids, input_mask, segment_ids])
# Concatenation
merged = layers.Concatenate(name='Concatenation')([image_side, text_side])
merged = layers.Dense(256, activation = 'relu', name='Dense_256')(merged)
merged = layers.Dropout(0.2)(merged)
merged = layers.Dense(128, activation = 'relu', name='Dense_128')(merged)
merged = layers.Dropout(0.2)(merged)
output = layers.Dense(nClasses, activation='softmax', name = "class")(merged)

model = models.Model([input_word_ids, input_mask, segment_ids, image_input], output)

# model.summary()

# Stochastic Gradient Descent optimizer
sgd = optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=False)

# Compile model
model.compile(loss='categorical_crossentropy',
              optimizer=sgd,
              metrics=['accuracy'])

# Setup callbacks, logs and early stopping condition
checkpoint_path = "/content/drive/My Drive/DL_project/combined/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5"
cp = callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy',save_best_only=True,verbose=1, mode='max')
csv_logger = callbacks.CSVLogger('/content/drive/My Drive/DL_project/combined/multimodel.log')
es = callbacks.EarlyStopping(patience = 3, restore_best_weights=True)

# Reduce learning rate if no improvement is observed
reduce_lr = callbacks.ReduceLROnPlateau(
    monitor='val_accuracy', factor=0.1, patience=1, min_lr=0.00001)



"""## data_train and data_set create"""

# Parameters setting: images width and height, depth, number if classes, input shape
batch_size =  30
img_width = 299
img_height = 299
depth = 3
max_length = 30 #Setup according to the text

nClasses = train.food.nunique()
Classes = train.food.unique()
input_shape = (img_width, img_height, depth)

# Cleaning of the texts

def preprocess_text(sen):
    # Removing html tags
    sentence = remove_tags(sen)
    # Remove punctuations and numbers
    sentence = re.sub('[^a-zA-Z]', ' ', sentence)
    # Single character removal
    sentence = re.sub(r"\s+[a-zA-Z]\s+", ' ', sentence)
    # Removing multiple spaces
    sentence = re.sub(r'\s+', ' ', sentence)
    sentence = sentence.lower()
    return sentence

def remove_tags(text):
    return TAG_RE.sub('', text)

TAG_RE = re.compile(r'<[^>]+>')
vec_preprocess_text = np.vectorize(preprocess_text)

def get_tokens(text, tokenizer):
  tokens = tokenizer.tokenize(text)
  tokens = ["[CLS]"] + tokens + ["[SEP]"]
  length = len(tokens)
  if length > max_length:
      tokens = tokens[:max_length]
  return tokens, length

def get_masks(text, tokenizer, max_length):
    """Mask for padding"""
    tokens, length = get_tokens(text, tokenizer)
    return np.asarray([1]*len(tokens) + [0] * (max_length - len(tokens)))
vec_get_masks = np.vectorize(get_masks, signature = '(),(),()->(n)')

def get_segments(text, tokenizer, max_length):
    """Segments: 0 for the first sequence, 1 for the second"""
    tokens, length = get_tokens(text, tokenizer)
    segments = []
    current_segment_id = 0
    for token in tokens:
        segments.append(current_segment_id)
        if token == "[SEP]":
            current_segment_id = 1
    return np.asarray(segments + [0] * (max_length - len(tokens)))
vec_get_segments = np.vectorize(get_segments, signature = '(),(),()->(n)')

def get_ids(text, tokenizer, max_length):
    """Token ids from Tokenizer vocab"""
    tokens, length = get_tokens(text, tokenizer)
    token_ids = tokenizer.convert_tokens_to_ids(tokens)
    input_ids = np.asarray(token_ids + [0] * (max_length-length))
    return input_ids
vec_get_ids = np.vectorize(get_ids, signature = '(),(),()->(n)')

def get_texts(path):
    path = path.decode('utf-8')
    parts = path.split(os.sep)
    image_name = parts[-1]
    is_train = parts[-3] == 'train'
    if is_train:
      df = train
    else:
      df = test

    text = df['text'][image_name]
    return text
vec_get_text = np.vectorize(get_texts)
def prepare_text(paths):
    #Preparing texts

    texts = vec_get_text(paths)

    text_array = vec_preprocess_text(texts)
    ids = vec_get_ids(text_array,
                      tokenizer,
                      max_length).squeeze().astype(np.int32)
    masks = vec_get_masks(text_array,
                          tokenizer,
                          max_length).squeeze().astype(np.int32)
    segments = vec_get_segments(text_array,
                                tokenizer,
                                max_length).squeeze().astype(np.int32)

    return ids, segments, masks

def clean(i, tokens):
  try:
    this_token = tokens[i]
    next_token = tokens[i+1]
  except:
    return tokens
  if '##' in next_token:
      tokens.remove(next_token)
      tokens[i] = this_token + next_token[2:]
      tokens = clean(i, tokens)
      return tokens
  else:
    i = i+1
    tokens = clean(i, tokens)
    return tokens

def clean_text(array):
  array = array[(array!=0) & (array != 101) & (array != 102)]
  tokens = tokenizer.convert_ids_to_tokens(array)
  tokens = clean(0, tokens)
  text = ' '.join(tokens)
  return text

# Images preprocessing
def load_image(path):
    path = path.decode('utf-8')
    image = cv2.imread(path)
    image = cv2.resize(image, (img_width, img_height))
    image = image/255
    image = image.astype(np.float32)
    parts = path.split(os.sep)
    labels = parts[-2] == Classes
    labels = labels.astype(np.int32)

    return image, labels

vec_load_image = np.vectorize(load_image, signature = '()->(r,c,d),(s)')

# Dataset creation

def prepare_data(paths):
    #Images and labels
    images, labels = tf.numpy_function(vec_load_image,
                                      [paths],
                                      [tf.float32,
                                        tf.int32])


    [ids, segments, masks, ] = tf.numpy_function(prepare_text,
                                              [paths],
                                              [tf.int32,
                                               tf.int32,
                                               tf.int32])
    images.set_shape([None, img_width, img_height, depth])
    labels.set_shape([None, nClasses])
    ids.set_shape([None, max_length])
    masks.set_shape([None, max_length])
    segments.set_shape([None, max_length])
    return ({"input_word_ids": ids,
             "input_mask": masks,
             "segment_ids": segments,
             "image": images},
            {"class": labels})


    return dataset

# Images loading using tf.data
def tf_data(path, batch_size):
    paths = tf.data.Dataset.list_files(path)
    paths = paths.batch(64)
    dataset = paths.map(prepare_data, tf.data.experimental.AUTOTUNE)
    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)
    dataset = dataset.unbatch()
    dataset = dataset.batch(batch_size)
    dataset = dataset.repeat()
    return dataset
data_train = tf_data('/content/drive/My Drive/pro/images/train/*/*.jpg', batch_size)
data_test = tf_data('/content/drive/My Drive/pro/images/test/*/*.jpg', batch_size)

# ip, op = next(iter(data_train))
# images = ip['image'][:16]
# input_word_ids = ip['input_word_ids'][:16]
# true_labels =  op['class'][:16]

# # Print images and related texts before classification
# i=1
# texts = [clean_text(array) for array in input_word_ids.numpy()]
# plt.figure(figsize=(30,30))
# for image, label, text in zip(images.numpy(), true_labels.numpy(), texts):
#       plt.subplot(4,4,i)
#       i+=1
#       image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
#       plt.imshow(image)
#       plt.axis('off')
#       plt.title("Text: {}\nCategory: {}".format(text, Classes[label.argmax(0)]))
# plt.show()

history = model.fit(data_train,
                   epochs=15,
                   steps_per_epoch = train.shape[0]//batch_size,
                   validation_data = data_test,
                   validation_steps = test.shape[0]//batch_size,
                   callbacks=[cp, csv_logger, reduce_lr])

# Model evaluation on test set
model.evaluate(data_test,steps = test.shape[0]//batch_size)
